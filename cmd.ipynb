{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3robMFhieCw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('path/to/sum')\n",
        "# os.chdir('/content/drive/MyDrive/adl3/summarization')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fz5yZ35ghiZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try different strategy"
      ],
      "metadata": {
        "id": "o751BpGRhifG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-k\n",
        "!python sum_pred.py\\\n",
        "--plan \"top_k\"\\\n",
        "--do_sample True\\\n",
        "--top_k 50"
      ],
      "metadata": {
        "id": "mVdgNvuxupxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-p\n",
        "!python sum_pred.py\\\n",
        "--plan \"top_p:\"\\\n",
        "--num_beams 1\\\n",
        "--do_sample True\\\n",
        "--top_p 0.95"
      ],
      "metadata": {
        "id": "om-vylp3uySN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temperature\n",
        "!python sum_pred.py\\\n",
        "--num_beams 1\\\n",
        "--do_sample True\\\n",
        "--top_p 0.95\\\n",
        "--temperature 1.5"
      ],
      "metadata": {
        "id": "ooCP6ZLBu3BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# greedy\n",
        "!python sum_pred.py\\\n",
        "--num_beams 1\\\n",
        "--do_sample False"
      ],
      "metadata": {
        "id": "Ky6WFLGTrEpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# beam search\n",
        "!python sum_pred.py\\\n",
        "--num_beams 2\\\n",
        "--do_sample False\\\n",
        "# --no_repeat_ngram_size 5"
      ],
      "metadata": {
        "id": "VwGjRUaAo8YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# count rouge"
      ],
      "metadata": {
        "id": "xryKmJrfoj-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('/content/drive/MyDrive/DL/adl3/summarization')'\n",
        "os.chdir('path/to/sum')\n",
        "os.system('git clone https://github.com/moooooser999/ADL22-HW3.git')\n",
        "os.system('pip install -e tw_rouge')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "742-_tZufGwz",
        "outputId": "a89f8f6f-4179-4e7c-81a9-adf0eb9bf4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "from ckiptagger import data_utils, construct_dictionary, WS\n",
        "import json\n",
        "\n",
        "ref_file = '../data/public.jsonl'\n",
        "\n",
        "ws = WS(\"./data\")\n",
        "\n",
        "def tokenize_and_join(sentences):\n",
        "    return [\" \".join(toks) for toks in ws(sentences)]\n",
        "rouge = Rouge()\n",
        "def get_rouge(preds, refs, avg=True, ignore_empty=False):\n",
        "    \"\"\"wrapper around: from rouge import Rouge\n",
        "    Args:\n",
        "        preds: string or list of strings\n",
        "        refs: string or list of strings\n",
        "        avg: bool, return the average metrics if set to True\n",
        "        ignore_empty: bool, ignore empty pairs if set to True\n",
        "    \"\"\"\n",
        "    if not isinstance(preds, list):\n",
        "        preds = [preds]\n",
        "    if not isinstance(refs, list):\n",
        "        refs = [refs]\n",
        "    preds, refs = tokenize_and_join(preds), tokenize_and_join(refs)\n",
        "    return rouge.get_scores(preds, refs, avg=avg, ignore_empty=ignore_empty)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d0c5f0-1022-4303-ae7a-44079c430b1b",
        "id": "Uaua3sLmfAoj"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_files = ['/content/drive/MyDrive/data/b08305056.jsonl']\n",
        "ref_file = '../data/public.jsonl'\n",
        "pred_file = 'result.jsonl'\n",
        "# target_files = ['path.to/your_target_file.jsonl']\n",
        "# ref_file = 'path/to/your_reference_file.jsonl'\n",
        "# pred_file = 'path/to/your/predict_result.jsonl'\n",
        "\n",
        "for target_file in target_files:\n",
        "  targetName = target_file.split('/')[-1]\n",
        "  refs, preds = {}, {}\n",
        "\n",
        "  with open(ref_file) as f:\n",
        "      public_data = [json.loads(line) for line in f.readlines()]\n",
        "  with open(target_file) as f:\n",
        "      submit_data = [json.loads(line) for line in f.readlines()]\n",
        "\n",
        "\n",
        "  with open(ref_file) as file:\n",
        "      for line in file:\n",
        "          line = json.loads(line)\n",
        "          refs[line['id']] = line['title'].strip() + '\\n'\n",
        "  with open(target_file) as file:\n",
        "      for line in file:\n",
        "          line = json.loads(line)\n",
        "          preds[line['id']] = line['title'].strip() + '\\n'\n",
        "\n",
        "  keys =  refs.keys()\n",
        "  refs = [refs[key] for key in keys]\n",
        "  preds = [preds[key] for key in keys]\n",
        "\n",
        "  pred_rouge = json.dumps(get_rouge(preds, refs), indent=2)\n",
        "  print(targetName)\n",
        "  print(pred_rouge)\n",
        "  with open(pred_file, 'w') as f:\n",
        "    json.dump(pred_rouge, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h38WV9UOfAol",
        "outputId": "8660d353-0533-42a5-ce41-01e7aebeb62c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b08305056.jsonl\n",
            "{\n",
            "  \"rouge-1\": {\n",
            "    \"r\": 0.2249765024280314,\n",
            "    \"p\": 0.27718181912847484,\n",
            "    \"f\": 0.23879090614315082\n",
            "  },\n",
            "  \"rouge-2\": {\n",
            "    \"r\": 0.09073602023481894,\n",
            "    \"p\": 0.10837938775687349,\n",
            "    \"f\": 0.09478028518929665\n",
            "  },\n",
            "  \"rouge-l\": {\n",
            "    \"r\": 0.2029598518995247,\n",
            "    \"p\": 0.2507953471469634,\n",
            "    \"f\": 0.2155561390883608\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxKTIO2OiqOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}